{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Development\n",
    "\n",
    "Use this notebook to load the model and then initialize, update, and test the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "from src.model import load_model, save_model\n",
    "from src.chat import SchoolChatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Add your Hugging Face token\n",
    "Options:\n",
    "1. Use login() and enter token when prompted. It won't ask for your token if you already logged in using the command: huggingface-cli login in the terminal.\n",
    "2. Set environment variable HUGGINGFACE_TOKEN\n",
    "3. Pass token directly (not recommended for shared notebooks)\n",
    "\"\"\"\n",
    "\n",
    "login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the model using functions from model.py\n",
    "\"\"\"\n",
    "\n",
    "model, tokenizer = load_model()\n",
    "\n",
    "# Test model loading\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Tokenizer loaded:\", type(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and test chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create chatbot instance using chat.py\n",
    "\"\"\"\n",
    "chatbot = SchoolChatbot(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test out generating some responses from the chatbot.\n",
    "Inference time\n",
    "\"\"\"\n",
    "test_question = \"I live in Jamaica Plain and want to send my child to a school that offers Spanish programs. What schools are available?\"\n",
    "\n",
    "print(f\"\\nQuestion: {test_question}\")\n",
    "response = chatbot.get_response(test_question)\n",
    "print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update pre-trained Llama to be a school choice chatbot\n",
    "\n",
    "This part is up to you! You might want to finetune the model, simply make a really good system prompt, use RAG, provide it boston school choice data somehow, etc. Be creative! If you choose to finetune the model, we recommend using LoRA.\n",
    "\n",
    "You can also feel free to do this in another script and then evaluate the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you update the model, you can use the `save_model` function from model.py to save the new model\n",
    "# Note: This might take a few minutes depending on your hardware. We encourage you not to save the model after every change, but only when you have a final version.\n",
    "save_model(model, tokenizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
